# -*- coding: utf-8 -*-
"""KNN_program.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eyMk0FcM5BGe8qv8awVxo43IHhScI8ab

**READING DATA**
"""

# Commented out IPython magic to ensure Python compatibility.
from mlxtend.plotting import plot_decision_regions
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()
import warnings
warnings.filterwarnings('ignore')
# %matplotlib inline
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from math import sqrt
import operator
df = pd.read_csv("/content/dataKNN.csv")
df.shape

df.head()

df.info()

"""Data Description"""

df.describe().T

print(df.isnull().sum())

"""**DATA VISUALISATION**"""

p = df.hist(figsize = (20,20))

df_copy = df.copy(deep = True)
df_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)

df['Glucose'].fillna(df['Glucose'].mean(), inplace = True)
df['BloodPressure'].fillna(df['BloodPressure'].mean(), inplace = True)
df['SkinThickness'].fillna(df['SkinThickness'].median(), inplace = True)
df['Insulin'].fillna(df['Insulin'].median(), inplace = True)
df['BMI'].fillna(df['BMI'].median(), inplace = True)

df.shape
df.columns

plt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.
p=sns.heatmap(df.corr(), annot=True,cmap ='RdYlGn')

"""**SCALING AND PREPROCESSING**"""

#Performing Scaling
sourcevars = df[['Pregnancies', 'Glucose', 'BloodPressure', 'Insulin',
       'BMI', 'DiabetesPedigreeFunction', 'Age']]
targetvar = df[['Outcome']]
sourcevars.head()

"""**PERFORMING FEATURE ABLATION**"""

#Preprocessing Data 
from sklearn.preprocessing import StandardScaler
scalar = StandardScaler()
df_1 = pd.DataFrame(scalar.fit_transform(sourcevars))
df_1.columns = [ 'Pregnencies','Glucose', 'BloodPressure', 'Insulin',
       'BMI', 'DiabetesPedigreeFunction', 'Age']

frames = [df_1, targetvar]
df = pd.concat(frames,axis =1)

print(df.shape)
df = df.dropna()
print(df.shape)

df.head()

"""**SPLITTING DATASET INTO TEST AND TRAIN**"""

#Splitting Dataset
train,test = train_test_split(df, test_size=0.2, random_state = 41)
N = len(train.columns) - 1
print(N)
dfs = np.split(train, np.arange(N, len(df.columns), N), axis=1)
x_train = dfs[0]
y_train = dfs[1]

dfp = np.split(test, np.arange(N, len(df.columns), N), axis=1)
x_test = dfp[0]
y_test = dfp[1]

x_train.shape
x_test.shape

"""**DEFINING KNN DISTANCE METRICS AND WEIGHTS**"""

## FUNCTION FOR CHEBYSHEV
def chebyshev_dist(data1,data2):
 return np.max(np.abs(data1-data2))
   
 
 ## FUNCTION FOR EUCLIDEAN
def euclideanDistance(data1, data2, length):
    distance = 0
    for x in range(length):
        distance += np.square(data1[x] - data2[x])
    return np.sqrt(distance)

# Defining our KNN model
def knn(trainingSet, testInstance, k):
 
    distances = {}
    sort = {}
    weights = {}
    length = testInstance.shape[1]
    #print(" Length is" + str(length))

    for x in range(len(trainingSet)):
        
        
        dist = euclideanDistance(testInstance, trainingSet.iloc[x], length)
        #dist = chebyshev_dist(testInstance, trainingSet.iloc[x])

        distances[x] = dist[0]
        weights[x] = 1/dist[0]
    #print(distances)
    #print(weights)  
    sorted_d = sorted(distances.items(), key=operator.itemgetter(1))
   # print(sorted_d)
    sorted_w = sorted(weights.items(), key=operator.itemgetter(1), reverse = True)
   # print(sorted_w)
    neighbors = []
   ## Taking K sorted distances
    for x in range(k):
        neighbors.append(sorted_d[x][0])
    classVotes = {}
    class_zero = 0
    class_one = 0
    #print(neighbors)
    for x in range(len(neighbors)):
        response = trainingSet.iloc[neighbors[x]][-1]
        #print("Response is")         
        #print(response)
        if response in classVotes:
            classVotes[response] += 1
        else:
            classVotes[response] = 1
        if(response == 0.0):
          class_zero = class_zero + sorted_w[neighbors[x]][1]
        elif(response == 1.0):
          class_one = class_one + sorted_w[neighbors[x]][1]


   # print(classVotes)
    if(class_one>class_zero):
      return 1.0
    else:
      return 0.0
   # sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)
   # return(sortedVotes[0][0])
 

predicted =[]
for i in range(len(test)):
  temp = pd.DataFrame(test.values[i])
  temp.head()
  result = knn(train,temp,10)
  predicted.append(result)

"""**PRINTING CLASSIFICATION REPORT**"""

from sklearn.metrics import classification_report
print(classification_report(y_test,predicted))

"""**ANALYSING RESULT(ROC/AUC)**"""

from sklearn import metrics
fpr, tpr, thresholds = metrics.roc_curve(y_test, predicted, pos_label=0)
# Print ROC curve
plt.plot(tpr,fpr)
plt.ylabel("True Positive Rate")
plt.xlabel("False Positive Rate")
plt.title("True Positive Rate Vs False Positive Rate")
plt.show()

# Print AUC
auc = np.trapz(fpr,tpr)
print('AUC:', auc)

"""**VISUALIZING KNN DATA**"""

from sklearn.neighbors import KNeighborsClassifier
knn =  KNeighborsClassifier(10)
knn.fit(x_train,y_train)
value = 20000
width = 20000
plot_decision_regions(sourcevars.values.astype(np.integer), targetvar.values.ravel().astype(np.integer), clf=knn, legend=2, 
                      filler_feature_values={2: value, 3: value, 4: value, 5: value, 6: value},
                      filler_feature_ranges={2: width, 3: width, 4: width, 5: width, 6: width},
                      X_highlight = x_test.values.astype(np.integer))


plt.title('KNN with Diabetes Data')
plt.xlim([-3,15])
plt.ylim([0,250])
plt.show()
